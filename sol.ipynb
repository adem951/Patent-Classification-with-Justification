{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des bibli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ali_nhs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ali_nhs/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')  # Nécessaire pour tokenizer les mots si besoin\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancement de la db avec que les colonnes importants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m         nrows\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Charger les données à partir du fichier CSV\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataBrevet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrevet.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Supprimer les colonnes inutiles pour la catégorisation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaim\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPC\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:616\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m--> 616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1782\u001b[0m, in \u001b[0;36mTextFileReader.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TextFileReader:\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1784\u001b[0m     exc_type: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mBaseException\u001b[39;00m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1785\u001b[0m     exc_value: \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1786\u001b[0m     traceback: TracebackType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1787\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Charger les données à partir du fichier CSV\n",
    "dataBrevet = pd.read_csv('brevet.csv')\n",
    "\n",
    "# Supprimer les colonnes inutiles pour la catégorisation\n",
    "columns_to_keep = ['claim', 'description', 'CPC']\n",
    "dataBrevet = dataBrevet[columns_to_keep]\n",
    "\n",
    "\n",
    "# Fusionner les colonnes 'claim' et 'description'\n",
    "dataBrevet['FusionClaimDescription'] = dataBrevet['claim'] + ' ' + dataBrevet['description']\n",
    "\n",
    "# Supprimer les colonnes 'claim' et 'description'\n",
    "dataBrevet.drop(['claim', 'description'], axis=1, inplace=True)\n",
    "\n",
    "# Afficher les premières lignes pour vérifier la structure des données échantillonnées\n",
    "print(dataBrevet.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définir les Fonctions de Nettoyage\n",
    "Définir les Fonctions de Nettoyage\n",
    "Définir les Fonctions de Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour nettoyer les balises XML\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Fonction pour nettoyer la ponctuation, convertir en minuscules, etc.\n",
    "def basic_cleaning(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Fonction pour nettoyer les stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "    \n",
    "# Fonction pour appliquer le stemming\n",
    "def apply_stemming(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 50000/50000 [1:04:30<00:00, 12.92it/s]\n",
      "100%|████████████████████████████████████| 50000/50000 [05:47<00:00, 143.86it/s]\n",
      "100%|███████████████████████████████████| 50000/50000 [00:46<00:00, 1081.58it/s]\n",
      "100%|███████████████████████████████████| 50000/50000 [00:47<00:00, 1043.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              FusionClaimDescription  \\\n",
      "0  method manufactur cover window display panel c...   \n",
      "1  compress screw appli compress bone joint compr...   \n",
      "2  cloth dryer 100 comprisinga case 4a dri drum 1...   \n",
      "3  diplex comprisinga filter pair constitut first...   \n",
      "4  method display electron program guide epg user...   \n",
      "\n",
      "                                                 CPC  \n",
      "0  ['B23K26-361', 'H04M1-0266', 'B23K26-402', 'G0...  \n",
      "1  ['A61B17-68', 'A61B17-888', 'A61B17-8685', 'A6...  \n",
      "2                        ['D06F58-206', 'D06F58-20']  \n",
      "3  ['H01P1-2138', 'H01P5-107', 'H01P1-2088', 'H01...  \n",
      "4      ['H04N21-4345', 'H04N21-4821', 'H04N21-4316']  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Nettoyer la colonne fusionnée\n",
    "dataBrevet['FusionClaimDescription'] = (\n",
    "    dataBrevet['FusionClaimDescription']\n",
    "    .progress_apply(apply_stemming)\n",
    "    .progress_apply(clean_text)\n",
    "    .progress_apply(basic_cleaning)\n",
    "    .progress_apply(remove_stopwords)\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# Afficher les données nettoyées\n",
    "print(dataBrevet[['FusionClaimDescription', 'CPC']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataBrevet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Sauvegarder les données nettoyées dans un fichier CSV\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataBrevet\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrevet_cleaned.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataBrevet' is not defined"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les données nettoyées dans un fichier CSV\n",
    "dataBrevet.to_csv('brevet_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPC</th>\n",
       "      <th>FusionClaimDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B23K26-361', 'H04M1-0266', 'B23K26-402', 'G0...</td>\n",
       "      <td>method manufactur cover window display panel c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['A61B17-68', 'A61B17-888', 'A61B17-8685', 'A6...</td>\n",
       "      <td>compress screw appli compress bone joint compr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['D06F58-206', 'D06F58-20']</td>\n",
       "      <td>cloth dryer 100 comprisinga case 4a dri drum 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['H01P1-2138', 'H01P5-107', 'H01P1-2088', 'H01...</td>\n",
       "      <td>diplex comprisinga filter pair constitut first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['H04N21-4345', 'H04N21-4821', 'H04N21-4316']</td>\n",
       "      <td>method display electron program guide epg user...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CPC  \\\n",
       "0  ['B23K26-361', 'H04M1-0266', 'B23K26-402', 'G0...   \n",
       "1  ['A61B17-68', 'A61B17-888', 'A61B17-8685', 'A6...   \n",
       "2                        ['D06F58-206', 'D06F58-20']   \n",
       "3  ['H01P1-2138', 'H01P5-107', 'H01P1-2088', 'H01...   \n",
       "4      ['H04N21-4345', 'H04N21-4821', 'H04N21-4316']   \n",
       "\n",
       "                              FusionClaimDescription  \n",
       "0  method manufactur cover window display panel c...  \n",
       "1  compress screw appli compress bone joint compr...  \n",
       "2  cloth dryer 100 comprisinga case 4a dri drum 1...  \n",
       "3  diplex comprisinga filter pair constitut first...  \n",
       "4  method display electron program guide epg user...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les données nettoyées\n",
    "dataBrevet_cleaned = pd.read_csv('brevet_cleaned.csv')\n",
    "dataBrevet_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPC</th>\n",
       "      <th>FusionClaimDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B23K26-361', 'H04M1-0266', 'B23K26-402', 'G0...</td>\n",
       "      <td>method manufactur cover window display panel c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['A61B17-68', 'A61B17-888', 'A61B17-8685', 'A6...</td>\n",
       "      <td>compress screw appli compress bone joint compr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['D06F58-206', 'D06F58-20']</td>\n",
       "      <td>cloth dryer 100 comprisinga case 4a dri drum 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['H01P1-2138', 'H01P5-107', 'H01P1-2088', 'H01...</td>\n",
       "      <td>diplex comprisinga filter pair constitut first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['H04N21-4345', 'H04N21-4821', 'H04N21-4316']</td>\n",
       "      <td>method display electron program guide epg user...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['F16D41-22', 'F16D43-22', 'F16D43-06', 'F16D1...</td>\n",
       "      <td>clutch assembl comprisingan output compon 12 i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CPC  \\\n",
       "0  ['B23K26-361', 'H04M1-0266', 'B23K26-402', 'G0...   \n",
       "1  ['A61B17-68', 'A61B17-888', 'A61B17-8685', 'A6...   \n",
       "2                        ['D06F58-206', 'D06F58-20']   \n",
       "3  ['H01P1-2138', 'H01P5-107', 'H01P1-2088', 'H01...   \n",
       "4      ['H04N21-4345', 'H04N21-4821', 'H04N21-4316']   \n",
       "5  ['F16D41-22', 'F16D43-22', 'F16D43-06', 'F16D1...   \n",
       "\n",
       "                              FusionClaimDescription  \n",
       "0  method manufactur cover window display panel c...  \n",
       "1  compress screw appli compress bone joint compr...  \n",
       "2  cloth dryer 100 comprisinga case 4a dri drum 1...  \n",
       "3  diplex comprisinga filter pair constitut first...  \n",
       "4  method display electron program guide epg user...  \n",
       "5  clutch assembl comprisingan output compon 12 i...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataBrevet_cleaned.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /opt/anaconda3/lib/python3.11/site-packages (0.9.3)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/anaconda3/lib/python3.11/site-packages (from fasttext) (2.12.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from fasttext) (68.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from fasttext) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [G, B, H]\n",
       "1              [A]\n",
       "2              [D]\n",
       "3              [H]\n",
       "4              [H]\n",
       "           ...    \n",
       "49995       [C, A]\n",
       "49996          [B]\n",
       "49997       [C, A]\n",
       "49998       [G, H]\n",
       "49999    [Y, B, F]\n",
       "Name: first_letters, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraire toutes les premières lettres de chaque catégorie CPC\n",
    "def extract_first_letters(cpc_list):\n",
    "    return list(set([code[0] for code in eval(cpc_list)]))\n",
    "\n",
    "dataBrevet_cleaned['first_letters'] = dataBrevet_cleaned['CPC'].apply(extract_first_letters)\n",
    "dataBrevet_cleaned['first_letters']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "train_data, test_data = train_test_split(dataBrevet_cleaned, test_size=0.3, random_state=1)\n",
    "\n",
    "# Fonction pour écrire les données dans un fichier au format FastText\n",
    "def write_fasttext_file(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        for _, row in data.iterrows():\n",
    "            labels = \" \".join([f\"__label__{label}\" for label in row['first_letters']])\n",
    "            f.write(f\"{labels} {row['FusionClaimDescription']}\\n\")\n",
    "\n",
    "# Préparer les fichiers pour FastText\n",
    "write_fasttext_file('train_first_letter.txt', train_data)\n",
    "write_fasttext_file('test_first_letter.txt', test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture et Prétraitement des Données : Chargement et tokenisation des données d'entraînement.\n",
    "Construction du Vocabulaire et des N-grammes : Création du vocabulaire et génération des n-grammes.\n",
    "Initialisation des Poids et des Embeddings : Initialisation des vecteurs de mots et des poids du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 219M words\n",
      "Number of words:  2525217\n",
      "Number of labels: 9\n",
      "Progress: 100.0% words/sec/thread: 1433877 lr:  0.000000 avg.loss:  0.450028 ETA:   0h 0m 0s  0h35m41s ETA:   0h35m 3s 0.478638 avg.loss:  1.201339 ETA:   0h35m 2s lr:  0.477814 avg.loss:  1.188484 ETA:   0h34m55s  0h33m37s 15.8% words/sec/thread: 1484031 lr:  0.420841 avg.loss:  0.786143 ETA:   0h29m35s 20.6% words/sec/thread: 1467179 lr:  0.396980 avg.loss:  0.718417 ETA:   0h28m14ss 37.8% words/sec/thread: 1490344 lr:  0.310851 avg.loss:  0.592389 ETA:   0h21m45s39s 38.7% words/sec/thread: 1483876 lr:  0.306330 avg.loss:  0.588434 ETA:   0h21m32s  0h21m23s 39.6% words/sec/thread: 1477856 lr:  0.302007 avg.loss:  0.584547 ETA:   0h21m19s1473123 lr:  0.288600 avg.loss:  0.572880 ETA:   0h20m26s1472740 lr:  0.281996 avg.loss:  0.567893 ETA:   0h19m58s% words/sec/thread: 1473154 lr:  0.174432 avg.loss:  0.506604 ETA:   0h12m21s% words/sec/thread: 1472926 lr:  0.173240 avg.loss:  0.505995 ETA:   0h12m16s 68.4% words/sec/thread: 1470450 lr:  0.157921 avg.loss:  0.499524 ETA:   0h11m12s 68.5% words/sec/thread: 1470431 lr:  0.157730 avg.loss:  0.499430 ETA:   0h11m11s 68.6% words/sec/thread: 1469871 lr:  0.156823 avg.loss:  0.499068 ETA:   0h11m 7s69.0% words/sec/thread: 1467460 lr:  0.155062 avg.loss:  0.498287 ETA:   0h11m 1s words/sec/thread: 1459274 lr:  0.116106 avg.loss:  0.483931 ETA:   0h 8m18s 8m 5s 77.5% words/sec/thread: 1459110 lr:  0.112680 avg.loss:  0.482706 ETA:   0h 8m 3s 77.6% words/sec/thread: 1459001 lr:  0.111967 avg.loss:  0.482498 ETA:   0h 8m 0s% words/sec/thread: 1449241 lr:  0.080166 avg.loss:  0.472063 ETA:   0h 5m46s1448902 lr:  0.078565 avg.loss:  0.471588 ETA:   0h 5m39s% words/sec/thread: 1448736 lr:  0.077385 avg.loss:  0.471213 ETA:   0h 5m34s84.8% words/sec/thread: 1448371 lr:  0.076077 avg.loss:  0.470843 ETA:   0h 5m28s 88.8% words/sec/thread: 1444229 lr:  0.055969 avg.loss:  0.464878 ETA:   0h 4m 2s89.1% words/sec/thread: 1443960 lr:  0.054564 avg.loss:  0.464414 ETA:   0h 3m56s 91.3% words/sec/thread: 1442296 lr:  0.043693 avg.loss:  0.461478 ETA:   0h 3m 9s 91.5% words/sec/thread: 1442085 lr:  0.042331 avg.loss:  0.461072 ETA:   0h 3m 3s 3s\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "# Entraîner le modèle FastText pour la première lettre des catégories CPC\n",
    "model_first_letter = fasttext.train_supervised(\n",
    "    input='train_first_letter.txt',\n",
    "    epoch=100, \n",
    "    lr=0.5, \n",
    "    wordNgrams=5,  \n",
    "    bucket=200000,\n",
    "    dim=100,\n",
    "    loss='softmax'\n",
    ")\n",
    "# Sauvegarder le modèle\n",
    "model_first_letter.save_model(\"model_first_letter.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Précision : Si votre modèle prédit 100 brevets comme étant de catégorie \"A\", mais que seulement 80 d'entre eux sont effectivement de catégorie \"A\", alors la précision est de 80%.\n",
    "Rappel : Si en réalité, il y a 100 brevets de catégorie \"A\", mais que votre modèle n'en a identifié que 80, alors le rappel est de 80%.\n",
    "Score F1 : Le score F1 pour ces valeurs de précision et de rappel serait de 80%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples : 15000\n",
      "Précision : 0.8664\n",
      "Rappel : 0.5875\n",
      "F1-score : 0.7002\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle\n",
    "model_first_letter = fasttext.load_model(\"model_first_letter.bin\")\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de test\n",
    "results = model_first_letter.test('test_first_letter.txt')\n",
    "\n",
    "# Extraire les métriques de performance\n",
    "num_examples, precision, recall = results\n",
    "print(f\"Nombre d'exemples : {num_examples}\")\n",
    "print(f\"Précision : {precision:.4f}\")\n",
    "print(f\"Rappel : {recall:.4f}\")\n",
    "\n",
    "# Calculer le F1-score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"F1-score : {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t•\tPrécision (Precision) : 0.8631\n",
    "\t•\tLa précision mesure la proportion de vraies prédictions positives parmi toutes les prédictions positives. Une précision de 0.8631 signifie que 86.31% des étiquettes prédites sont correctes.\n",
    "\t•\tRappel (Recall) : 0.5853\n",
    "\t•\tLe rappel mesure la proportion de vraies prédictions positives parmi toutes les instances positives réelles. Un rappel de 0.5853 signifie que le modèle récupère 58.53% des étiquettes positives réelles.\n",
    "\t•\tF1-score : 0.7002\n",
    "\t•\tLe F1-score est la moyenne harmonique de la précision et du rappel. Il est particulièrement utile lorsque vous avez besoin d’un équilibre entre précision et rappel.\n",
    "\n",
    "\t•\tPrécision élevée, mais rappel relativement faible :\n",
    "\t•\tCela signifie que, bien que le modèle fasse peu d’erreurs lorsqu’il fait une prédiction positive (haute précision), il manque beaucoup d’instances positives réelles (faible rappel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusionClaimDescription: tinplat copper termin materi comprising substrat made copper copper alloy intermedi zinc layer form substrate made zinc alloy ha thick less 010 500 tin layer made tin tin alloy form intermedi zinc layer proport length occupi lowangl grain boundari less 2 30 respect total length crystal grain boundariesth tinplat copper termin materi accord claim 1 wherein corros potenti respect silversilv chlorid electrod 500 mv less 900 mvth tinplat copper termin materi accord claim 1 wherein intermedi zinc layer compris one among nickel iron manganese molybdenum cobalt cadmium lead addit element content percentag zinc intermedi zinc layer less 65 mass 95 massth tinplat copper termin materi accord claim 1 wherein averag crystal grain size tin layer less 05 80 mth tinplat copper termin materi accord claim 1 wherein surfac metalliczinc layer provid tin layerth tinplat copper termin materi accord claim 5 wherein surface metalliczinc layer ha zinc concentr less 5 40 thick less 10 nm 100 nm term sio2th tin\n",
      "CPC: ['C25D7-00', 'C22C18-00', 'C25D5-10', 'C25D5-12', 'C25D5-617', 'H01R13-03', 'H01R4-62', 'C25D3-30', 'C25D3-12', 'C25D3-565', 'H01R4-185']\n"
     ]
    }
   ],
   "source": [
    "# Exemple de texte pour la prédiction après le nettoyage et la fusion des colonnes\n",
    "sample_text = dataBrevet_cleaned.iloc[20000]['FusionClaimDescription'][:1000]\n",
    "cpc_sample = dataBrevet_cleaned.iloc[20000]['CPC']\n",
    "print(\"FusionClaimDescription:\", sample_text)\n",
    "print(\"CPC:\", cpc_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted first letters: H, C\n",
      "Predicted probabilities: 0.5075941681861877, 0.44304996728897095\n"
     ]
    }
   ],
   "source": [
    "# Exemple donnée dans le notion\n",
    "cleaned_text = clean_text(sample_text)\n",
    "cleaned_text = basic_cleaning(cleaned_text)\n",
    "cleaned_text = remove_stopwords(cleaned_text)\n",
    "\n",
    "# Prédire les premières lettres avec les 1 labels les plus probables\n",
    "predictions = model_first_letter.predict(cleaned_text, k=2)\n",
    "\n",
    "# Extraire les labels prédits et les nettoyer\n",
    "predicted_first_letters = [label.replace(\"__label__\", \"\") for label in predictions[0]]\n",
    "predicted_probabilities = predictions[1]\n",
    "print(f\"Predicted first letters: {', '.join(predicted_first_letters)}\")\n",
    "print(f\"Predicted probabilities: {', '.join(map(str, predicted_probabilities))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted first letters: H, C\n",
      "Predicted probabilities: 0.5075941681861877, 0.44304996728897095\n",
      "\n",
      "Words that influenced the prediction:\n",
      "\n",
      "Label: __label__H\n",
      "  Word: accord, Impact: 0.0458\n",
      "  Word: sio2th, Impact: 0.0398\n",
      "  Word: accord, Impact: 0.0360\n",
      "  Word: one, Impact: 0.0343\n",
      "  Word: tin, Impact: 0.0340\n",
      "  Word: 5, Impact: 0.0331\n",
      "  Word: 1, Impact: 0.0326\n",
      "  Word: iron, Impact: 0.0305\n",
      "  Word: less, Impact: 0.0297\n",
      "  Word: accord, Impact: 0.0281\n",
      "\n",
      "Label: __label__C\n",
      "  Word: 500, Impact: 0.1797\n",
      "  Word: addit, Impact: 0.1787\n",
      "  Word: percentag, Impact: 0.1676\n",
      "  Word: element, Impact: 0.1513\n",
      "  Word: compris, Impact: 0.1291\n",
      "  Word: materi, Impact: 0.1288\n",
      "  Word: materi, Impact: 0.1269\n",
      "  Word: zinc, Impact: 0.1194\n",
      "  Word: materi, Impact: 0.1187\n",
      "  Word: tin, Impact: 0.1168\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fonction pour expliquer la prédiction\n",
    "def explain_prediction(model, text, top_k=2, threshold=0.01, top_n=10):\n",
    "    # Prédiction initiale\n",
    "    initial_predictions = model.predict(text, k=top_k)\n",
    "    initial_probs = initial_predictions[1]\n",
    "\n",
    "    words = text.split()\n",
    "    word_importances = {label: [] for label in initial_predictions[0]}\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        perturbed_text = \" \".join(words[:i] + words[i+1:])\n",
    "        perturbed_predictions = model.predict(perturbed_text, k=top_k)\n",
    "        perturbed_probs = perturbed_predictions[1]\n",
    "\n",
    "        for j in range(top_k):\n",
    "            label = initial_predictions[0][j]\n",
    "            importance = initial_probs[j] - perturbed_probs[j]\n",
    "            if importance >= threshold:\n",
    "                word_importances[label].append((word, importance))\n",
    "\n",
    "    # Trier les mots par importance pour chaque label et garder les top_n mots\n",
    "    for label in word_importances:\n",
    "        word_importances[label] = sorted(word_importances[label], key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    return word_importances\n",
    "\n",
    "\n",
    "# Prédire les premières lettres avec les labels les plus probables\n",
    "predictions = model_first_letter.predict(cleaned_text, k=2)\n",
    "\n",
    "# Extraire les labels prédits et les nettoyer\n",
    "predicted_first_letters = [label.replace(\"__label__\", \"\") for label in predictions[0]]\n",
    "predicted_probabilities = predictions[1]\n",
    "print(f\"Predicted first letters: {', '.join(predicted_first_letters)}\")\n",
    "print(f\"Predicted probabilities: {', '.join(map(str, predicted_probabilities))}\")\n",
    "\n",
    "# Expliquer la prédiction\n",
    "word_importances = explain_prediction(model_first_letter, cleaned_text, top_k=2, threshold=0.01, top_n=10)\n",
    "\n",
    "# Afficher les mots importants pour chaque lettre prédite\n",
    "print(\"\\nWords that influenced the prediction:\")\n",
    "for label in word_importances:\n",
    "    print(f\"\\nLabel: {label}\")\n",
    "    for word, importance in word_importances[label]:\n",
    "        print(f\"  Word: {word}, Impact: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1145   98   41    8    7   43  101   33    3]\n",
      " [ 109 1351   34    8   19  185   87  111   16]\n",
      " [ 234  221 1338   16    3   42   75  138   64]\n",
      " [  19   37   14  101    3   11    6    1    2]\n",
      " [  28   84    1    0  146   53   16    8    0]\n",
      " [  36   60    3    1   11  644   12   57   19]\n",
      " [ 174  285   23    4   12   69 2939  664   52]\n",
      " [  18   38    9    0    4   20  177 2192   24]\n",
      " [  41  243   28    5    9  287   31  471  278]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.63      0.77      0.70      1479\n",
      "           B       0.56      0.70      0.62      1920\n",
      "           C       0.90      0.63      0.74      2131\n",
      "           D       0.71      0.52      0.60       194\n",
      "           E       0.68      0.43      0.53       336\n",
      "           F       0.48      0.76      0.59       843\n",
      "           G       0.85      0.70      0.77      4222\n",
      "           H       0.60      0.88      0.71      2482\n",
      "           Y       0.61      0.20      0.30      1393\n",
      "\n",
      "    accuracy                           0.68     15000\n",
      "   macro avg       0.67      0.62      0.62     15000\n",
      "weighted avg       0.71      0.68      0.67     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour obtenir les étiquettes prédictes pour chaque ligne du fichier de test\n",
    "def get_predicted_labels(model, test_file):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    with open(test_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            true_label = parts[0].replace(\"__label__\", \"\")\n",
    "            text = \" \".join(parts[1:])\n",
    "            prediction = model.predict(text, k=1)\n",
    "            predicted_label = prediction[0][0].replace(\"__label__\", \"\")\n",
    "            true_labels.append(true_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "# Obtenir les étiquettes véritables et prédictes\n",
    "true_labels, predicted_labels = get_predicted_labels(model_first_letter, 'test_first_letter.txt')\n",
    "\n",
    "# Convertir les étiquettes en numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Générer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Générer le rapport de classification\n",
    "class_report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "# Afficher la matrice de confusion et le rapport de classification\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vrai c'est pas mal, 0,7 de f1-score pas mal pour la première lettre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAINTENANT ON VA PASSER AU DEUX DIGIT APRÈS LA LETTRE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             [G02, G06, H04, B23]\n",
       "1                            [A61]\n",
       "2                            [D06]\n",
       "3                            [H01]\n",
       "4                            [H04]\n",
       "                   ...            \n",
       "49995                   [C09, A61]\n",
       "49996                   [B60, B65]\n",
       "49997                   [C07, A61]\n",
       "49998              [G06, G07, H04]\n",
       "49999    [B33, B08, F01, B01, Y02]\n",
       "Name: first_letter_and_digits, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Fonction pour extraire les deux chiffres après la première lettre de chaque catégorie CPC\n",
    "def extract_first_letter_and_digits(cpc_list):\n",
    "    return list(set([code[:3] for code in eval(cpc_list)]))\n",
    "\n",
    "dataBrevet_cleaned['first_letter_and_digits'] = dataBrevet_cleaned['CPC'].apply(extract_first_letter_and_digits)\n",
    "dataBrevet_cleaned['first_letter_and_digits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des répertoires pour les fichiers d'entraînement\n",
    "if not os.path.exists('train_filesLetter'):\n",
    "    os.makedirs('train_filesLetter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les fichiers texte pour chaque lettre spécifique\n",
    "valid_letters = 'ABCDEFGHY'\n",
    "for letter in valid_letters:\n",
    "    with open(f'train_filesLetter/train_{letter}.txt', 'w') as f:\n",
    "        for _, row in dataBrevet_cleaned.iterrows():\n",
    "            if letter in row['first_letters']:\n",
    "                labels = \" \".join([f\"__label__{label}\" for label in row['first_letter_and_digits'] if label.startswith(letter)])\n",
    "                f.write(f\"{labels} {row['FusionClaimDescription']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 55M words\n",
      "Number of words:  1160619\n",
      "Number of labels: 15\n",
      "Progress: 100.0% words/sec/thread: 4017882 lr:  0.000000 avg.loss:  0.149851 ETA:   0h 0m 0s\n",
      "Read 61M words\n",
      "Number of words:  774293\n",
      "Number of labels: 37\n",
      "Progress: 100.0% words/sec/thread: 4150257 lr:  0.000000 avg.loss:  0.384881 ETA:   0h 0m 0s 28.2% words/sec/thread: 4123533 lr:  0.717856 avg.loss:  0.784362 ETA:   0h 1m16s\n",
      "Read 52M words\n",
      "Number of words:  1440214\n",
      "Number of labels: 20\n",
      "Progress: 100.0% words/sec/thread: 3834647 lr:  0.000000 avg.loss:  0.395720 ETA:   0h 0m 0s 68.4% words/sec/thread: 3816780 lr:  0.316293 avg.loss:  0.465831 ETA:   0h 0m31s\n",
      "Read 4M words\n",
      "Number of words:  128310\n",
      "Number of labels: 9\n",
      "Progress: 100.0% words/sec/thread: 4205055 lr:  0.000000 avg.loss:  0.396862 ETA:   0h 0m 0s\n",
      "Read 6M words\n",
      "Number of words:  116386\n",
      "Number of labels: 7\n",
      "Progress: 100.0% words/sec/thread: 4411943 lr:  0.000000 avg.loss:  0.220189 ETA:   0h 0m 0s\n",
      "Read 29M words\n",
      "Number of words:  337858\n",
      "Number of labels: 18\n",
      "Progress: 100.0% words/sec/thread: 4304644 lr:  0.000000 avg.loss:  0.439207 ETA:   0h 0m 0s52.5% words/sec/thread: 4347248 lr:  0.475380 avg.loss:  0.571273 ETA:   0h 0m22s% words/sec/thread: 4325222 lr:  0.341325 avg.loss:  0.519807 ETA:   0h 0m16s\n",
      "Read 98M words\n",
      "Number of words:  1103463\n",
      "Number of labels: 14\n",
      "Progress: 100.0% words/sec/thread:  979590 lr:  0.000000 avg.loss:  0.289626 ETA:   0h 0m 0s379946 lr:  0.673969 avg.loss:  0.495827 ETA:   0h20m53s\n",
      "Read 116M words\n",
      "Number of words:  1136192\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 4506409 lr:  0.000000 avg.loss:  0.130875 ETA:   0h 0m 0s\n",
      "Read 40M words\n",
      "Number of words:  618793\n",
      "Number of labels: 3\n",
      "Progress: 100.0% words/sec/thread: 4371899 lr:  0.000000 avg.loss:  0.032033 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Entraîner et sauvegarder un modèle FastText pour chaque lettre spécifique\n",
    "for letter in valid_letters:\n",
    "    train_file = f'train_filesLetter/train_{letter}.txt'\n",
    "    if os.path.exists(train_file):\n",
    "        model = fasttext.train_supervised(input=train_file, epoch=50, lr=1.0, wordNgrams=2, bucket=200000, dim=100, loss='softmax')\n",
    "        model.save_model(f\"model_{letter}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category_and_explain(text, top_k=3, threshold=0.01):\n",
    "    # Prédire les premières lettres avec les k labels les plus probables\n",
    "    first_letter_predictions = model_first_letter.predict(text, k=top_k)\n",
    "    predicted_first_letters = [label.replace(\"__label__\", \"\") for label in first_letter_predictions[0]]\n",
    "    predicted_first_probs = first_letter_predictions[1]\n",
    "    \n",
    "    # Prédictions pour les deux premiers chiffres pour chaque lettre prédite\n",
    "    digits_predictions = {}\n",
    "    explanations = {}\n",
    "    for i, letter in enumerate(predicted_first_letters):\n",
    "        model_path = f\"model_{letter}.bin\"\n",
    "        model_specific = fasttext.load_model(model_path)\n",
    "        digit_predictions = model_specific.predict(text, k=top_k)\n",
    "        predicted_digits = [label.replace(\"__label__\", \"\") for label in digit_predictions[0]]\n",
    "        predicted_probs = digit_predictions[1]\n",
    "        digits_predictions[letter] = list(zip(predicted_digits, predicted_probs))\n",
    "\n",
    "        # Obtenir les mots les plus influents pour chaque lettre et chaque chiffre\n",
    "        explanations[letter] = {}\n",
    "        first_letter_explanation = explain_prediction(model_first_letter, text, top_k, threshold)\n",
    "        digit_explanation = explain_prediction(model_specific, text, top_k, threshold)\n",
    "        explanations[letter]['first_letter'] = first_letter_explanation\n",
    "        explanations[letter]['digits'] = digit_explanation\n",
    "    \n",
    "    return predicted_first_letters, predicted_first_probs, digits_predictions, explanations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted first letters and their probabilities:\n",
      "Letter: H, Probability: 0.5076\n",
      "Letter: C, Probability: 0.4430\n",
      "Letter: B, Probability: 0.0459\n",
      "\n",
      "Predicted digits for each letter and their probabilities:\n",
      "\n",
      "Letter: H\n",
      "  Digits: H01, Probability: 1.0000\n",
      "  Digits: H05, Probability: 0.0000\n",
      "  Digits: H10, Probability: 0.0000\n",
      "\n",
      "Letter: C\n",
      "  Digits: C22, Probability: 0.9849\n",
      "  Digits: C25, Probability: 0.0145\n",
      "  Digits: C23, Probability: 0.0007\n",
      "\n",
      "Letter: B\n",
      "  Digits: B32, Probability: 0.9592\n",
      "  Digits: B23, Probability: 0.0190\n",
      "  Digits: B22, Probability: 0.0189\n",
      "\n",
      "Words that influenced the prediction:\n",
      "\n",
      "Label: H\n",
      "  First letter influence:\n",
      "    Word: accord, Impact: 0.0458\n",
      "    Word: sio2th, Impact: 0.0398\n",
      "    Word: accord, Impact: 0.0360\n",
      "    Word: one, Impact: 0.0343\n",
      "    Word: tin, Impact: 0.0340\n",
      "    Word: 5, Impact: 0.0331\n",
      "    Word: 1, Impact: 0.0326\n",
      "    Word: iron, Impact: 0.0305\n",
      "    Word: less, Impact: 0.0297\n",
      "    Word: accord, Impact: 0.0281\n",
      "  Digits influence:\n",
      "\n",
      "Label: C\n",
      "  First letter influence:\n",
      "    Word: 500, Impact: 0.1797\n",
      "    Word: addit, Impact: 0.1787\n",
      "    Word: percentag, Impact: 0.1676\n",
      "    Word: element, Impact: 0.1513\n",
      "    Word: compris, Impact: 0.1291\n",
      "    Word: materi, Impact: 0.1288\n",
      "    Word: materi, Impact: 0.1269\n",
      "    Word: zinc, Impact: 0.1194\n",
      "    Word: materi, Impact: 0.1187\n",
      "    Word: tin, Impact: 0.1168\n",
      "  Digits influence:\n",
      "    Digits: C22, Word: alloy, Impact: 0.0195\n",
      "    Digits: C22, Word: alloy, Impact: 0.0126\n",
      "    Digits: C22, Word: alloy, Impact: 0.0102\n",
      "\n",
      "Label: B\n",
      "  First letter influence:\n",
      "    Word: zinc, Impact: 0.0213\n",
      "    Word: layer, Impact: 0.0181\n",
      "    Word: 500, Impact: 0.0181\n",
      "    Word: 2, Impact: 0.0177\n",
      "    Word: element, Impact: 0.0176\n",
      "    Word: percentag, Impact: 0.0175\n",
      "    Word: tin, Impact: 0.0174\n",
      "    Word: respect, Impact: 0.0156\n",
      "    Word: layer, Impact: 0.0150\n",
      "    Word: content, Impact: 0.0147\n",
      "  Digits influence:\n",
      "    Digits: B32, Word: claim, Impact: 0.0374\n",
      "    Digits: B32, Word: claim, Impact: 0.0374\n",
      "    Digits: B32, Word: claim, Impact: 0.0374\n",
      "    Digits: B32, Word: claim, Impact: 0.0374\n",
      "    Digits: B32, Word: layer, Impact: 0.0339\n",
      "    Digits: B32, Word: content, Impact: 0.0270\n",
      "    Digits: B32, Word: made, Impact: 0.0229\n",
      "    Digits: B32, Word: layer, Impact: 0.0221\n",
      "    Digits: B32, Word: layer, Impact: 0.0219\n",
      "    Digits: B32, Word: made, Impact: 0.0211\n",
      "    Digits: B22, Word: iron, Impact: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Prédire et expliquer les prédictions pour un texte donné\n",
    "predicted_first_letters, predicted_first_probs, digits_predictions, explanations = predict_category_and_explain(cleaned_text)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Predicted first letters and their probabilities:\")\n",
    "for letter, prob in zip(predicted_first_letters, predicted_first_probs):\n",
    "    print(f\"Letter: {letter}, Probability: {prob:.4f}\")\n",
    "\n",
    "print(\"\\nPredicted digits for each letter and their probabilities:\")\n",
    "for letter, digit_list in digits_predictions.items():\n",
    "    print(f\"\\nLetter: {letter}\")\n",
    "    for digit, prob in digit_list:\n",
    "        print(f\"  Digits: {digit}, Probability: {prob:.4f}\")\n",
    "\n",
    "print(\"\\nWords that influenced the prediction:\")\n",
    "for letter in explanations:\n",
    "    print(f\"\\nLabel: {letter}\")\n",
    "    print(\"  First letter influence:\")\n",
    "    for word, importance in explanations[letter]['first_letter'].get(f\"__label__{letter}\", []):\n",
    "        print(f\"    Word: {word}, Impact: {importance:.4f}\")\n",
    "    print(\"  Digits influence:\")\n",
    "    for digit in explanations[letter]['digits']:\n",
    "        for word, importance in explanations[letter]['digits'][digit]:\n",
    "            print(f\"    Digits: {digit.replace('__label__', '')}, Word: {word}, Impact: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir le f1 score oobligé cette etape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des répertoires pour les fichiers de test\n",
    "if not os.path.exists('test_filesLetter'):\n",
    "    os.makedirs('test_filesLetter')\n",
    "\n",
    "# Créer les fichiers texte pour chaque lettre spécifique\n",
    "for letter in valid_letters:\n",
    "    with open(f'test_filesLetter/test_{letter}.txt', 'w') as f:\n",
    "        for _, row in dataBrevet_cleaned.iterrows():\n",
    "            if letter in row['first_letters']:\n",
    "                labels = \" \".join([f\"__label__{label}\" for label in row['first_letter_and_digits'] if label.startswith(letter)])\n",
    "                f.write(f\"{labels} {row['FusionClaimDescription']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision (Digits) : 0.9320\n",
      "Rappel (Digits) : 0.9239\n",
      "F1-score (Digits) : 0.9240\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, test_file):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Lire le fichier de test et obtenir les prédictions\n",
    "    with open(test_file, 'r') as f:\n",
    "        for line in f:\n",
    "            labels, text = line.split(' ', 1)\n",
    "            true_labels = labels.split()\n",
    "            prediction = model.predict(text.strip())[0]\n",
    "            y_true.extend(true_labels)\n",
    "            y_pred.extend(prediction)\n",
    "\n",
    "    # Nettoyer les étiquettes prédits\n",
    "    y_pred_clean = [label.replace(\"__label__\", \"\") for label in y_pred]\n",
    "    y_true_clean = [label.replace(\"__label__\", \"\") for label in y_true]\n",
    "\n",
    "    # Calculer les métriques\n",
    "    precision = precision_score(y_true_clean, y_pred_clean, average='weighted')\n",
    "    recall = recall_score(y_true_clean, y_pred_clean, average='weighted')\n",
    "    f1 = f1_score(y_true_clean, y_pred_clean, average='weighted')\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Évaluer les performances pour les deux premiers chiffres de chaque lettre prédite\n",
    "precision_digits = []\n",
    "recall_digits = []\n",
    "f1_digits = []\n",
    "\n",
    "for letter in valid_letters:\n",
    "    test_file = f'test_filesLetter/test_{letter}.txt'\n",
    "    model_specific = fasttext.load_model(f'model_{letter}.bin')\n",
    "    precision, recall, f1 = evaluate_model(model_specific, test_file)\n",
    "    precision_digits.append(precision)\n",
    "    recall_digits.append(recall)\n",
    "    f1_digits.append(f1)\n",
    "\n",
    "# Calculer les métriques moyennes\n",
    "average_precision_digits = sum(precision_digits) / len(precision_digits)\n",
    "average_recall_digits = sum(recall_digits) / len(recall_digits)\n",
    "average_f1_digits = sum(f1_digits) / len(f1_digits)\n",
    "\n",
    "print(f\"Précision (Digits) : {average_precision_digits:.4f}\")\n",
    "print(f\"Rappel (Digits) : {average_recall_digits:.4f}\")\n",
    "print(f\"F1-score (Digits) : {average_f1_digits:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import fasttext\n",
    "import streamlit as st\n",
    "import fasttext\n",
    "from utils import clean_text, basic_cleaning, remove_stopwords, predict_category_and_explain,explain_prediction\n",
    "import os\n",
    "\n",
    "\n",
    "# Interface utilisateur\n",
    "st.title(\"Prédiction de Catégories de Brevets\")\n",
    "user_input = st.text_area(\"Entrez le texte du brevet ici:\")\n",
    "if st.button(\"Prédire\"):\n",
    "    if user_input:\n",
    "        predicted_first_letter, _ = model_first_letter.predict(cleaned_text, k=1)\n",
    "        predicted_first_letter = predicted_first_letter[0].replace(\"__label__\", \"\")\n",
    "        \n",
    "        st.write(f\"Première lettre prédite : {predicted_first_letter}\")\n",
    "        \n",
    "        if predicted_first_letter in models_digits:\n",
    "            model_digits = models_digits[predicted_first_letter]\n",
    "            predicted_digits, digit_probs = model_digits.predict(cleaned_text, k=3)\n",
    "            predicted_digits = [digit.replace(\"__label__\", \"\") for digit in predicted_digits]\n",
    "            \n",
    "            st.write(f\"Chiffres prédits : {', '.join(predicted_digits)}\")\n",
    "\n",
    "            # Explication pour la première lettre\n",
    "            word_importances_first_letter = explain_prediction(model_first_letter, cleaned_text)\n",
    "            st.write(\"Mots influents pour la première lettre :\")\n",
    "            for label in word_importances_first_letter:\n",
    "                st.write(f\"\\nLabel: {label}\")\n",
    "                for word, importance in word_importances_first_letter[label]:\n",
    "                    st.write(f\"  Mot: {word}, Impact: {importance:.4f}\")\n",
    "\n",
    "            # Explication pour les chiffres prédits\n",
    "            word_importances_digits = explain_prediction(model_digits, cleaned_text)\n",
    "            st.write(\"Mots influents pour les chiffres prédits :\")\n",
    "            for label in word_importances_digits:\n",
    "                st.write(f\"\\nLabel: {label}\")\n",
    "                for word, importance in word_importances_digits[label]:\n",
    "                    st.write(f\"  Mot: {word}, Impact: {importance:.4f}\")\n",
    "        else:\n",
    "            st.write(\"Modèle pour les deux premiers chiffres non trouvé.\")\n",
    "    else:\n",
    "        st.write(\"Veuillez entrer un texte pour la prédiction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
